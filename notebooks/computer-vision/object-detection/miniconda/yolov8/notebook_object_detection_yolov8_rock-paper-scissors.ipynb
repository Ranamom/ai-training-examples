{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cd36251-0e58-4e3a-8f45-3d917b07033f",
   "metadata": {},
   "source": [
    "# TUTORIAL: Train YOLOv8 for Rock / Paper / Scissors game\n",
    "\n",
    "*A guide to use Transfer Learning on YOLOv8 in order to play to the Rock / Paper / Scissors game through an AI Notebook.*\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The purpose of this tutorial is to show how it is possible to train YOLOv8 to play to the game \"rock paper scissors\"!\n",
    "YOLOv8 is an object detection algorithm. Although closely related to image classification, object detection performs image classification on a more precise scale. Object detection locates and categorizes features in images.\n",
    "\n",
    "It is based on the YOLOv8 open source [repository](https://github.com/ultralytics/ultralytics).\n",
    "\n",
    "## Code\n",
    "\n",
    "The different steps are as follow:\n",
    "\n",
    "- Download the Rock / Paper / Scissors Dataset\n",
    "- Clone YOLOv8 repository\n",
    "- Install YOLOv8 dependencies\n",
    "- Import dependencies and check GPU availability\n",
    "- Define the number of classes and YOLOv8 model architecture\n",
    "- Recover YOLOv8 weights\n",
    "- Run YOLOv8 training on Rock / Paper / Scissors dataset\n",
    "- Display results of YOLOv8 training on Rock / Paper / Scissors dataset\n",
    "- Test your YOLOv8 custom model on the Rock / Paper / Scissors test dataset\n",
    "- Run YOLOv8 inference on new images\n",
    "- Export trained weights for future inference\n",
    "\n",
    "# Download the Rock / Paper / Scissors Dataset\n",
    "\n",
    "The Rock / Paper / Scissors Dataset is available on <a href=\"https://universe.roboflow.com/roboflow-58fyf/rock-paper-scissors-sxsw\">Roboflow</a>.\n",
    "\n",
    "If you want to use this **Public Dataset** on the tutorial, follow the next requirements:\n",
    "\n",
    "- create a Roboflow account\n",
    "- click on `Download` in order to download the dataset\n",
    "- select`YOLO v8 PyTorch` format\n",
    "- choose the method `show download code`\n",
    "\n",
    "You will get a URL (`<dataset_url>`) that will allow you to download your dataset directly inside the notebook.\n",
    "\n",
    "Finally, replace `<dataset_url>` with yours in the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb77c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to the folder corresponding to your object container\n",
    "%mkdir /workspace/data/rock-paper-scissors\n",
    "%cd /workspace/data/rock-paper-scissors\n",
    "\n",
    "!curl -L \"<dataset_url>\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip /workspace/data/rock-paper-scissors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66323553",
   "metadata": {},
   "source": [
    "## Install YOLOv8 dependencies\n",
    "The easiest way to use YOLOv8 is to install Python dependency for ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ultralytics -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606369e1",
   "metadata": {},
   "source": [
    "## Import dependencies and check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1778eb7-9a6c-49f2-b834-820300cd5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "import shutil, os\n",
    "\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45871a43",
   "metadata": {},
   "source": [
    "## Recover YOLOv8 weights\n",
    "\n",
    "In this tutorial, we will do **Transfer Learning** based on a YOLOv8 model pre-trained on the <a href=\"https://cocodataset.org/\">COCO dataset</a>.\n",
    "\n",
    "**How to define Transfer Learning?**\n",
    "\n",
    "For both humans and machines, learning something new takes time and practice. However, it is easier to perform similar tasks to those already learned. As with humans, AI will be able to identify patterns from previous knowledge and apply them to new learning.\n",
    "\n",
    "If a model is trained on a database, there is no need to re-train the model from scratch to fit a new set of similar data.\n",
    "\n",
    "Main advantages of Transfer Learning:\n",
    "\n",
    "- saving resources\n",
    "- improving efficiency\n",
    "- model training facilitation\n",
    "- saving time\n",
    "\n",
    "**What is the COCO dataset?**\n",
    "\n",
    "COCO is a large-scale object detection, segmentation, and also captioning dataset. COCO has several features:\n",
    "\n",
    "- Object segmentation\n",
    "- Recognition in context\n",
    "- Superpixel stuff segmentation\n",
    "- 330K images\n",
    "- 1.5 million object instances\n",
    "- 80 object categories\n",
    "- 91 stuff categories\n",
    "- 5 captions per image\n",
    "- 250 000 people with keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8569c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the YOLOv8 weights\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c6463",
   "metadata": {},
   "source": [
    "## Run YOLOv8 training on ASL Letters Dataset\n",
    "\n",
    "Parameters definitions:\n",
    "\n",
    "- device: cuda device.\n",
    "- data: refers to the path to the yaml file.\n",
    "- epochs: refers to the number of training epochs. An epoch corresponds to one cycle through the full training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf46a6-4cdb-4589-8e48-8655be005759",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.train(data='/workspace/data/rock-paper-scissors/data.yaml', device=0, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8f515a",
   "metadata": {},
   "source": [
    "> **Here you have an example for one epoch.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33862e1a",
   "metadata": {},
   "source": [
    "## Display results of YOLOv8 training on Rock / Paper / Scissors dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b756b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display images\n",
    "from IPython.display import Image, clear_output\n",
    "Image(filename='/workspace/data/rock-paper-scissors/runs/detect/train/results.png', width=1000)  # view results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7f109",
   "metadata": {},
   "source": [
    "#### Graphs and functions explanation\n",
    "\n",
    "**Loss functions:**\n",
    "\n",
    "*For the training set:*\n",
    "\n",
    "- Box: loss due to a box prediction not exactly covering an object.\n",
    "- Objectness: loss due to a wrong box-object IoU **[1]** prediction.\n",
    "- Classification: loss due to deviations from predicting ‘1’ for the correct classes and ‘0’ for all the other classes for the object in that box.\n",
    "\n",
    "*For the valid set (the same loss functions as for the training data):*\n",
    "\n",
    "- val Box\n",
    "- val Objectness\n",
    "- val Classification\n",
    "\n",
    "**Precision & Recall:**\n",
    "\n",
    "- Precision: measures how accurate are the predictions. It is the percentage of your correct predictions\n",
    "- Recall: measures how good it finds all the positives\n",
    "\n",
    "*How to calculate Precision and Recall ?*\n",
    "\n",
    "**Accuracy functions:**\n",
    "\n",
    "mAP (mean Average Precision) compares the ground-truth bounding box to the detected box and returns a score. The higher the score, the more accurate the model is in its detections.\n",
    "\n",
    "- mAP@ 0.5：when IoU is set to 0.5, the AP **[2]** of all pictures of each category is calculated, and then all categories are averaged : mAP\n",
    "- mAP@ 0.5:0.95：represents the average mAP at different IoU thresholds (from 0.5 to 0.95 in steps of 0.05)\n",
    "\n",
    "**[1] IoU (Intersection over Union)** = measures the overlap between two boundaries. It is used to measure how much the predicted boundary overlaps with the ground truth\n",
    "\n",
    "*How to calculate IoU ?*\n",
    "\n",
    "**[2] AP (Average precision)** = popular metric in measuring the accuracy of object detectors. It computes the average precision value for recall value over 0 to 1\n",
    "\n",
    "## Test your YOLOv8 custom model on the Rock / Paper / Scissors test dataset\n",
    "\n",
    "Perform inference on the contents of the `/workspace/data/test` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2babbd-0f4e-4981-b11c-4b05a7be266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the weights\n",
    "exportedWeights = model.export()\n",
    "print(exportedWeights)\n",
    "\n",
    "# Create the new model based on the weights\n",
    "savedModel = YOLO(exportedWeights)\n",
    "\n",
    "# Test of the new model\n",
    "savedModel.predict('/workspace/data/rock-paper-scissors/test/images/20220216_221856_jpg.rf.c551cb3856f480cba36d6aa58e3300cd.jpg', verbose=True, save=True, conf=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfee193",
   "metadata": {},
   "source": [
    "## Run YOLOv8 inference on new images\n",
    "\n",
    "⚠️ Upload a new image in the `/workspace/new-images/` folder ⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedModel.predict('/workspace/data/rock-paper-scissors/new-images/scissors4.jpg', verbose=True, save=True, conf=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63349687",
   "metadata": {},
   "source": [
    "You can show the resulting images: `/workspace/data/rock-paper-scissors/runs/detect/predict`\n",
    "\n",
    "## Export trained weights for future inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the final model to the /workspace/model folder\n",
    "if not os.path.isdir('/workspace/model/rock-paper-scissors/'):\n",
    "    %mkdir /workspace/model/rock-paper-scissors\n",
    "shutil.copy(exportedWeights, '/workspace/model/rock-paper-scissors/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
